{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce45466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "#TypedDicts like State define what fields are expected in the Python object \n",
    "#passed between steps, functions, or graph nodes.\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    query: str\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///finances.db\")\n",
    " \n",
    " \n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    " \n",
    " \n",
    "\n",
    "# 3) Prompt that shows schema + samples and enforces SQL-only\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a SQLite expert. Given an input question, create a syntactically correct {dialect} query to run.\\n\"\n",
    "     \"Unless otherwise specified, do not return more than {top_k} rows.\\n\"\n",
    "     \"Use only the following tables, columns, and sample rows:\\n{table_info}\\n\\n\"\n",
    "     \"Return only a single SQL statement. No explanations, no markdown, no code fences.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 4) Chain with required variables (create_sql_query_chain injects table_info/top_k)\n",
    "chain = create_sql_query_chain(llm, db, prompt=prompt)\n",
    "\n",
    "# 5) Defensive extractor to strip any stray prose/markdown\n",
    "SQL_PATTERN = re.compile(r'(?is)\\\\b(SELECT|WITH|INSERT|UPDATE|DELETE)\\\\b.*?;', re.DOTALL)\n",
    "\n",
    "def extract_sql(text: str) -> str:\n",
    "    cleaned = text.replace(\"``````\", \"\").strip()\n",
    "    m = SQL_PATTERN.search(cleaned.replace(\"\\n\", \" \"))\n",
    "    return m.group(0).strip() if m else cleaned\n",
    "\n",
    "\n",
    "system_message = \"\"\"\n",
    "Given an input question, create a syntactically correct {dialect} query to\n",
    "run to help find the answer. Unless the user specifies in his question a\n",
    "specific number of examples they wish to obtain, always limit your query to\n",
    "at most {top_k} results. You can order the results by a relevant column to\n",
    "return the most interesting examples in the database.\n",
    "\n",
    "Never query for all the columns from a specific table, only ask for a the\n",
    "few relevant columns given the question.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema\n",
    "description. Be careful to not query for columns that do not exist. Also,\n",
    "pay attention to which column is in which table.\n",
    "\n",
    "Note: All dates in this database are stored as text strings in the exact format 'YYYY-MM-DD' (for example, '2025-07-14').\n",
    "When filtering by month and year, use:\n",
    "    strftime('%Y-%m', date_column) = 'YYYY-MM'\n",
    "Do not use LIKE with '-MM-YYYY'; always use '%Y-%m' extracted from the date.\n",
    "\n",
    " \n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Question: {input}\"\n",
    "\n",
    "query_prompt_template = ChatPromptTemplate(\n",
    "    [(\"system\", system_message), (\"user\", user_prompt)]\n",
    ")\n",
    "    \n",
    "\n",
    " \n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "\n",
    "def write_query(state: State):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke(\n",
    "        {\n",
    "            \"dialect\": db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return {\"query\": result[\"query\"]}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5098ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = write_query({\"question\": \"How much money did I spend in February 2024?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c42df74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "890f7b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': '[(-1000.0,), (-6.99,), (-0.82,), (-30.47,), (-0.58,), (-21.51,), (-1102.32,), (-2.99,), (-2.0,), (-1024.8,), (-12.81,), (-4.13,), (-7.5,), (-0.36,), (-13.3,), (-1.15,), (-42.44,), (-16.24,), (-2.74,), (-9.29,), (-12.99,), (-12.0,), (-16.27,), (-23.52,), (-119.9,), (-36.31,), (-34.16,), (-9.38,), (-8.72,), (-8.99,), (-12.89,), (-61.79,), (-105.72,), (-8.99,), (-42.51,), (-3.83,), (1400.0,), (807.86,), (-0.18,), (-6.54,), (-0.09,), (-3.39,), (-3.0,), (-40.05,), (-21.63,), (-60.0,), (-11.9,), (-4.24,), (-21.52,), (-11.15,), (-0.6,), (-22.18,), (-100.0,), (-8.85,), (-10.0,), (-9.6,), (-6.5,), (-2.0,), (-10.99,), (105.98,), (-19.56,), (-4.87,), (-180.3,), (-184.66,), (-37.22,), (-58.93,), (-14.4,), (-2.85,), (-5.4,), (-836.3,), (-16.65,), (-25.0,), (836.3,), (-296.45,), (-16.99,), (-349.45,), (-7.99,), (-4.9,), (-8.1,), (-5.0,), (-82.0,), (-20.68,), (-2.0,), (-8.64,), (105.98,), (-58.0,), (-15.0,), (-42.15,), (-12.5,), (-70.0,), (-0.38,), (-13.91,), (-1.73,), (-64.0,), (-6.3,), (-4.1,), (-230.18,), (-0.15,), (-5.54,), (-0.37,), (-13.87,), (-2.5,), (-140.0,), (-2.5,), (-70.0,), (-7.19,), (-9.3,), (-2.0,), (-59.64,), (-88.25,), (-50.0,), (-2.6,), (-2.4,), (-56.0,), (-8.49,), (-0.36,), (-13.22,), (-2.3,), (-3.7,), (-7.39,), (-29.16,), (-158.73,), (-5.44,), (-5.33,), (-2.15,), (-14.6,), (-98.01,), (-3583.53,), (2169.0,), (-1.0,), (-0.5,), (-18.52,)]'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query({\"query\": sqlQuery})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77c77bfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     response = llm.invoke(prompt)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: response.content}\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mgenerate_answer\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_answer\u001b[39m(state: State):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Answer question using retrieved information as context.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m     prompt = (\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGiven the following user question, corresponding SQL query, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand SQL result, answer the user question.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSQL Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSQL Result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     10\u001b[39m     response = llm.invoke(prompt)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: response.content}\n",
      "\u001b[31mKeyError\u001b[39m: 'query'"
     ]
    }
   ],
   "source": [
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f\"Question: {state['question']}\\n\"\n",
    "        f\"SQL Query: {state['query']}\\n\"\n",
    "        f\"SQL Result: {state['result']}\"\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "generate_answer(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain)",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
